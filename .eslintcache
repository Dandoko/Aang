[{"/mnt/e/media/downloads/aang-app/src/index.js":"1","/mnt/e/media/downloads/aang-app/src/reportWebVitals.js":"2","/mnt/e/media/downloads/aang-app/src/App.js":"3","/mnt/e/media/downloads/aang-app/src/Pose.js":"4","/mnt/e/media/downloads/aang-app/src/utilities.js":"5","/mnt/e/media/downloads/aang-app/src/PoseComponent.js":"6","/mnt/e/Media/Downloads/aang-app/src/index.js":"7","/mnt/e/Media/Downloads/aang-app/src/reportWebVitals.js":"8","/mnt/e/Media/Downloads/aang-app/src/App.js":"9","/mnt/e/Media/Downloads/aang-app/src/utilities.js":"10","/mnt/e/Media/Downloads/aang-app/src/PoseComponent.js":"11","/mnt/e/Media/Downloads/aang-app/src/Pose.js":"12","/mnt/e/Media/Downloads/aang-app/src/Model.js":"13"},{"size":500,"mtime":1610776548010,"results":"14","hashOfConfig":"15"},{"size":362,"mtime":1610776548025,"results":"16","hashOfConfig":"15"},{"size":4879,"mtime":1610823820128,"results":"17","hashOfConfig":"15"},{"size":123,"mtime":1610824129545,"results":"18","hashOfConfig":"15"},{"size":7125,"mtime":1610777389076,"results":"19","hashOfConfig":"15"},{"size":205,"mtime":1610824126486,"results":"20","hashOfConfig":"15"},{"size":500,"mtime":1610776548010,"results":"21","hashOfConfig":"22"},{"size":362,"mtime":1610776548025,"results":"23","hashOfConfig":"22"},{"size":4979,"mtime":1610831955576,"results":"24","hashOfConfig":"22"},{"size":7125,"mtime":1610777389076,"results":"25","hashOfConfig":"22"},{"size":221,"mtime":1610825095985,"results":"26","hashOfConfig":"22"},{"size":123,"mtime":1610824129545,"results":"27","hashOfConfig":"22"},{"size":150,"mtime":1610832219302,"results":"28","hashOfConfig":"22"},{"filePath":"29","messages":"30","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"31"},"15k3dlk",{"filePath":"32","messages":"33","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"31"},{"filePath":"34","messages":"35","errorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"36","usedDeprecatedRules":"31"},{"filePath":"37","messages":"38","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"39","messages":"40","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"41","usedDeprecatedRules":"31"},{"filePath":"42","messages":"43","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"44","messages":"45","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"46"},"145wfdv",{"filePath":"47","messages":"48","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"46"},{"filePath":"49","messages":"50","errorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"51","messages":"52","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"41","usedDeprecatedRules":"46"},{"filePath":"53","messages":"54","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"46"},{"filePath":"55","messages":"56","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"46"},{"filePath":"57","messages":"58","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"/mnt/e/media/downloads/aang-app/src/index.js",[],["59","60"],"/mnt/e/media/downloads/aang-app/src/reportWebVitals.js",[],"/mnt/e/media/downloads/aang-app/src/App.js",["61","62","63","64"],"// 1. Install dependencies DONE\n// 2. Import dependencies DONE\n// 3. Setup webcam and canvas DONE\n// 4. Define references to those DONE\n// 5. Load posenet DONE\n// 6. Detect function DONE\n// 7. Drawing utilities from tensorflow DONE\n// 8. Draw functions DONE\n\nimport React, { useRef } from \"react\";\nimport \"./App.css\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as posenet from \"@tensorflow-models/posenet\";\nimport Webcam from \"react-webcam\";\nimport { drawKeypoints, drawSkeleton } from \"./utilities\";\nimport PoseComponent from \"./PoseComponent\";\nimport Pose from \"./Pose\";\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  var poses = []; // stores 10 most recent poses - nose, eyes, ...\n  const maxPoses = 10;\n\n  var calibratedPose = new Pose();\n  var currPose = new Pose();\n\n  var calibrated = false;\n\n  //  Load posenet\n  const runPosenet = async () => {\n    const net = await posenet.load({\n      inputResolution: { width: 640, height: 480 },\n      scale: 0.8,\n    });\n    //\n    setInterval(() => {\n      detect(net);\n    }, 1000);\n  };\n\n  const detect = async (net) => {\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      if (calibrated) {\n        console.log(calibratedPose);\n        drawCanvas(calibratedPose, video, videoWidth, videoHeight, canvasRef);\n        return;\n      }\n\n      // Make Detections\n      const pose = await net.estimateSinglePose(video);\n      //console.log(pose);\n\n      addPose(pose);\n\n      drawCanvas(pose, video, videoWidth, videoHeight, canvasRef);\n    }\n  };\n\n  // replaces oldest pose with newest pose\n  const addPose = (pose) => {\n    if (poses.length >= maxPoses) {\n      poses.shift();\n    }\n\n    poses.push(pose);\n\n    if (!calibrated && poses.length == maxPoses) {\n      calibratePose(0.6);\n    }\n  };\n\n  const ergoComputation = () => {\n    if (poses.length < maxPoses) {\n      return;\n    }\n\n    //PostureChecker();\n    //ArmChecker();\n  };\n\n  const calibratePose = (minConfidence) => {\n    calibrated = true;\n    // loops 17 times for 17 keypoints (body parts)\n    for (var i = 0; i < poses[0][\"keypoints\"].length; i++) {\n      // initialize component\n      var poseComponent = new PoseComponent();\n      console.log(poses[0][\"keypoints\"][i]);\n      poseComponent.part = poses[0][\"keypoints\"][i].part;\n\n      var count = 0;\n\n      for (var j = 0; j < maxPoses; j++) {\n        console.log(\"Pose\" + j); //TODO Empty PoseCompnents\n        console.log(poses[j]);\n        if (poses[j][\"keypoints\"][i].score >= minConfidence) {\n          // get sum for mean\n          poseComponent.position.x += poses[j][\"keypoints\"][i].position.x;\n          poseComponent.position.y += poses[j][\"keypoints\"][i].position.y;\n          poseComponent.score += poses[j][\"keypoints\"][i].score;\n\n          count++;\n\n          console.log(count);\n        }\n      }\n\n      if (count == 0) {\n        poseComponent.position.x = 0;\n        poseComponent.position.y = 0;\n        poseComponent.score = 0;\n      } else {\n        poseComponent.position.x /= count;\n        poseComponent.position.y /= count;\n        poseComponent.score /= count;\n      }\n\n      console.log(poseComponent);\n\n      calibratedPose[\"keypoints\"].push(poseComponent);\n      currPose[\"keypoints\"].push(poseComponent);\n    }\n\n    console.log(\"Calibrating done\");\n    console.log(calibratedPose);\n  };\n\n  const drawCanvas = (pose, video, videoWidth, videoHeight, canvas) => {\n    const ctx = canvas.current.getContext(\"2d\");\n    canvas.current.width = videoWidth;\n    canvas.current.height = videoHeight;\n\n    drawKeypoints(pose[\"keypoints\"], 0.6, ctx);\n    drawSkeleton(pose[\"keypoints\"], 0.7, ctx);\n  };\n\n  runPosenet();\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <Webcam\n          ref={webcamRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n","/mnt/e/media/downloads/aang-app/src/Pose.js",[],"/mnt/e/media/downloads/aang-app/src/utilities.js",["65"],"/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * https://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport * as posenet from \"@tensorflow-models/posenet\";\r\nimport * as tf from \"@tensorflow/tfjs\";\r\n\r\nconst color = \"aqua\";\r\nconst boundingBoxColor = \"red\";\r\nconst lineWidth = 2;\r\n\r\nexport const tryResNetButtonName = \"tryResNetButton\";\r\nexport const tryResNetButtonText = \"[New] Try ResNet50\";\r\nconst tryResNetButtonTextCss = \"width:100%;text-decoration:underline;\";\r\nconst tryResNetButtonBackgroundCss = \"background:#e61d5f;\";\r\n\r\nfunction isAndroid() {\r\n  return /Android/i.test(navigator.userAgent);\r\n}\r\n\r\nfunction isiOS() {\r\n  return /iPhone|iPad|iPod/i.test(navigator.userAgent);\r\n}\r\n\r\nexport function isMobile() {\r\n  return isAndroid() || isiOS();\r\n}\r\n\r\nfunction setDatGuiPropertyCss(propertyText, liCssString, spanCssString = \"\") {\r\n  var spans = document.getElementsByClassName(\"property-name\");\r\n  for (var i = 0; i < spans.length; i++) {\r\n    var text = spans[i].textContent || spans[i].innerText;\r\n    if (text == propertyText) {\r\n      spans[i].parentNode.parentNode.style = liCssString;\r\n      if (spanCssString !== \"\") {\r\n        spans[i].style = spanCssString;\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nexport function updateTryResNetButtonDatGuiCss() {\r\n  setDatGuiPropertyCss(\r\n    tryResNetButtonText,\r\n    tryResNetButtonBackgroundCss,\r\n    tryResNetButtonTextCss\r\n  );\r\n}\r\n\r\n/**\r\n * Toggles between the loading UI and the main canvas UI.\r\n */\r\nexport function toggleLoadingUI(\r\n  showLoadingUI,\r\n  loadingDivId = \"loading\",\r\n  mainDivId = \"main\"\r\n) {\r\n  if (showLoadingUI) {\r\n    document.getElementById(loadingDivId).style.display = \"block\";\r\n    document.getElementById(mainDivId).style.display = \"none\";\r\n  } else {\r\n    document.getElementById(loadingDivId).style.display = \"none\";\r\n    document.getElementById(mainDivId).style.display = \"block\";\r\n  }\r\n}\r\n\r\nfunction toTuple({ y, x }) {\r\n  return [y, x];\r\n}\r\n\r\nexport function drawPoint(ctx, y, x, r, color) {\r\n  ctx.beginPath();\r\n  ctx.arc(x, y, r, 0, 2 * Math.PI);\r\n  ctx.fillStyle = color;\r\n  ctx.fill();\r\n}\r\n\r\n/**\r\n * Draws a line on a canvas, i.e. a joint\r\n */\r\nexport function drawSegment([ay, ax], [by, bx], color, scale, ctx) {\r\n  ctx.beginPath();\r\n  ctx.moveTo(ax * scale, ay * scale);\r\n  ctx.lineTo(bx * scale, by * scale);\r\n  ctx.lineWidth = lineWidth;\r\n  ctx.strokeStyle = color;\r\n  ctx.stroke();\r\n}\r\n\r\n/**\r\n * Draws a pose skeleton by looking up all adjacent keypoints/joints\r\n */\r\nexport function drawSkeleton(keypoints, minConfidence, ctx, scale = 1) {\r\n  const adjacentKeyPoints = posenet.getAdjacentKeyPoints(\r\n    keypoints,\r\n    minConfidence\r\n  );\r\n\r\n  adjacentKeyPoints.forEach((keypoints) => {\r\n    drawSegment(\r\n      toTuple(keypoints[0].position),\r\n      toTuple(keypoints[1].position),\r\n      color,\r\n      scale,\r\n      ctx\r\n    );\r\n  });\r\n}\r\n\r\n/**\r\n * Draw pose keypoints onto a canvas\r\n */\r\nexport function drawKeypoints(keypoints, minConfidence, ctx, scale = 1) {\r\n  for (let i = 0; i < keypoints.length; i++) {\r\n    const keypoint = keypoints[i];\r\n\r\n    if (keypoint.score < minConfidence) {\r\n      continue;\r\n    }\r\n\r\n    const { y, x } = keypoint.position;\r\n    drawPoint(ctx, y * scale, x * scale, 3, color);\r\n  }\r\n}\r\n\r\n/**\r\n * Draw the bounding box of a pose. For example, for a whole person standing\r\n * in an image, the bounding box will begin at the nose and extend to one of\r\n * ankles\r\n */\r\nexport function drawBoundingBox(keypoints, ctx) {\r\n  const boundingBox = posenet.getBoundingBox(keypoints);\r\n\r\n  ctx.rect(\r\n    boundingBox.minX,\r\n    boundingBox.minY,\r\n    boundingBox.maxX - boundingBox.minX,\r\n    boundingBox.maxY - boundingBox.minY\r\n  );\r\n\r\n  ctx.strokeStyle = boundingBoxColor;\r\n  ctx.stroke();\r\n}\r\n\r\n/**\r\n * Converts an arary of pixel data into an ImageData object\r\n */\r\nexport async function renderToCanvas(a, ctx) {\r\n  const [height, width] = a.shape;\r\n  const imageData = new ImageData(width, height);\r\n\r\n  const data = await a.data();\r\n\r\n  for (let i = 0; i < height * width; ++i) {\r\n    const j = i * 4;\r\n    const k = i * 3;\r\n\r\n    imageData.data[j + 0] = data[k + 0];\r\n    imageData.data[j + 1] = data[k + 1];\r\n    imageData.data[j + 2] = data[k + 2];\r\n    imageData.data[j + 3] = 255;\r\n  }\r\n\r\n  ctx.putImageData(imageData, 0, 0);\r\n}\r\n\r\n/**\r\n * Draw an image on a canvas\r\n */\r\nexport function renderImageToCanvas(image, size, canvas) {\r\n  canvas.width = size[0];\r\n  canvas.height = size[1];\r\n  const ctx = canvas.getContext(\"2d\");\r\n\r\n  ctx.drawImage(image, 0, 0);\r\n}\r\n\r\n/**\r\n * Draw heatmap values, one of the model outputs, on to the canvas\r\n * Read our blog post for a description of PoseNet's heatmap outputs\r\n * https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5\r\n */\r\nexport function drawHeatMapValues(heatMapValues, outputStride, canvas) {\r\n  const ctx = canvas.getContext(\"2d\");\r\n  const radius = 5;\r\n  const scaledValues = heatMapValues.mul(tf.scalar(outputStride, \"int32\"));\r\n\r\n  drawPoints(ctx, scaledValues, radius, color);\r\n}\r\n\r\n/**\r\n * Used by the drawHeatMapValues method to draw heatmap points on to\r\n * the canvas\r\n */\r\nfunction drawPoints(ctx, points, radius, color) {\r\n  const data = points.buffer().values;\r\n\r\n  for (let i = 0; i < data.length; i += 2) {\r\n    const pointY = data[i];\r\n    const pointX = data[i + 1];\r\n\r\n    if (pointX !== 0 && pointY !== 0) {\r\n      ctx.beginPath();\r\n      ctx.arc(pointX, pointY, radius, 0, 2 * Math.PI);\r\n      ctx.fillStyle = color;\r\n      ctx.fill();\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * Draw offset vector values, one of the model outputs, on to the canvas\r\n * Read our blog post for a description of PoseNet's offset vector outputs\r\n * https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5\r\n */\r\n// export function drawOffsetVectors(\r\n//     heatMapValues, offsets, outputStride, scale = 1, ctx) {\r\n//   const offsetPoints =\r\n//       posenet.singlePose.getOffsetPoints(heatMapValues, outputStride, offsets);\r\n\r\n//   const heatmapData = heatMapValues.buffer().values;\r\n//   const offsetPointsData = offsetPoints.buffer().values;\r\n\r\n//   for (let i = 0; i < heatmapData.length; i += 2) {\r\n//     const heatmapY = heatmapData[i] * outputStride;\r\n//     const heatmapX = heatmapData[i + 1] * outputStride;\r\n//     const offsetPointY = offsetPointsData[i];\r\n//     const offsetPointX = offsetPointsData[i + 1];\r\n\r\n//     drawSegment(\r\n//         [heatmapY, heatmapX], [offsetPointY, offsetPointX], color, scale, ctx);\r\n//   }\r\n// }\r\n","/mnt/e/media/downloads/aang-app/src/PoseComponent.js",[],"/mnt/e/Media/Downloads/aang-app/src/index.js",[],["66","67"],"/mnt/e/Media/Downloads/aang-app/src/reportWebVitals.js",[],"/mnt/e/Media/Downloads/aang-app/src/App.js",["68","69","70","71"],"/mnt/e/Media/Downloads/aang-app/src/utilities.js",["72"],"/mnt/e/Media/Downloads/aang-app/src/PoseComponent.js",[],"/mnt/e/Media/Downloads/aang-app/src/Pose.js",[],"/mnt/e/Media/Downloads/aang-app/src/Model.js",[],{"ruleId":"73","replacedBy":"74"},{"ruleId":"75","replacedBy":"76"},{"ruleId":"77","severity":1,"message":"78","line":12,"column":13,"nodeType":"79","messageId":"80","endLine":12,"endColumn":15},{"ruleId":"81","severity":1,"message":"82","line":82,"column":37,"nodeType":"83","messageId":"84","endLine":82,"endColumn":39},{"ruleId":"77","severity":1,"message":"85","line":87,"column":9,"nodeType":"79","messageId":"80","endLine":87,"endColumn":24},{"ruleId":"81","severity":1,"message":"82","line":122,"column":17,"nodeType":"83","messageId":"84","endLine":122,"endColumn":19},{"ruleId":"81","severity":1,"message":"82","line":45,"column":14,"nodeType":"83","messageId":"84","endLine":45,"endColumn":16},{"ruleId":"73","replacedBy":"86"},{"ruleId":"75","replacedBy":"87"},{"ruleId":"77","severity":1,"message":"78","line":12,"column":13,"nodeType":"79","messageId":"80","endLine":12,"endColumn":15},{"ruleId":"81","severity":1,"message":"82","line":83,"column":37,"nodeType":"83","messageId":"84","endLine":83,"endColumn":39},{"ruleId":"77","severity":1,"message":"85","line":88,"column":9,"nodeType":"79","messageId":"80","endLine":88,"endColumn":24},{"ruleId":"81","severity":1,"message":"82","line":123,"column":17,"nodeType":"83","messageId":"84","endLine":123,"endColumn":19},{"ruleId":"81","severity":1,"message":"82","line":45,"column":14,"nodeType":"83","messageId":"84","endLine":45,"endColumn":16},"no-native-reassign",["88"],"no-negated-in-lhs",["89"],"no-unused-vars","'tf' is defined but never used.","Identifier","unusedVar","eqeqeq","Expected '===' and instead saw '=='.","BinaryExpression","unexpected","'ergoComputation' is assigned a value but never used.",["88"],["89"],"no-global-assign","no-unsafe-negation"]